{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "016761cb",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-09-24T03:42:47.918625Z",
     "iopub.status.busy": "2025-09-24T03:42:47.918215Z",
     "iopub.status.idle": "2025-09-24T03:42:56.487841Z",
     "shell.execute_reply": "2025-09-24T03:42:56.486822Z"
    },
    "papermill": {
     "duration": 8.574706,
     "end_time": "2025-09-24T03:42:56.489392",
     "exception": false,
     "start_time": "2025-09-24T03:42:47.914686",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import time\n",
    "import os\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bb2b5b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-24T03:42:56.494802Z",
     "iopub.status.busy": "2025-09-24T03:42:56.494379Z",
     "iopub.status.idle": "2025-09-24T03:42:56.518241Z",
     "shell.execute_reply": "2025-09-24T03:42:56.517398Z"
    },
    "papermill": {
     "duration": 0.028651,
     "end_time": "2025-09-24T03:42:56.519947",
     "exception": false,
     "start_time": "2025-09-24T03:42:56.491296",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ECGTrainer:\n",
    "    def __init__(self, model, train_loader, val_loader, device='cuda', \n",
    "                 num_classes=5, class_weights=None, lr=1e-3,weight_decay=1e-4):\n",
    "        self.model = model.to(device)\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.device = device\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        # Loss function with class weights for imbalanced ECG data\n",
    "        if class_weights is not None:\n",
    "            class_weights = torch.tensor(class_weights, dtype=torch.float32).to(device)\n",
    "        self.criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "        \n",
    "        # Optimizer and scheduler\n",
    "        self.optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "        self.scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            self.optimizer, mode='min', factor=0.5, patience=5, verbose=True\n",
    "        )\n",
    "        \n",
    "        # Training history\n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "        self.val_accuracies = []\n",
    "        self.val_f1_scores = []\n",
    "        self.best_val_loss = float('inf')\n",
    "        self.best_model_state = None\n",
    "        self.patience_counter = 0\n",
    "    \n",
    "    def train_epoch(self):\n",
    "        self.model.train()\n",
    "        total_loss = 0\n",
    "        total_correct = 0\n",
    "        total_samples = 0\n",
    "        \n",
    "        for batch_idx, (data, target) in enumerate(self.train_loader):\n",
    "            data, target = data.to(self.device), target.to(self.device)\n",
    "            \n",
    "            self.optimizer.zero_grad()\n",
    "            output = self.model(data)\n",
    "            loss = self.criterion(output, target)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1)\n",
    "            self.optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            pred = output.argmax(dim=1)\n",
    "            total_correct += pred.eq(target).sum().item()\n",
    "            total_samples += target.size(0)\n",
    "            \n",
    "            if batch_idx % 50 == 0:\n",
    "                print(f'Train Batch {batch_idx}: Loss: {loss.item():.4f}, '\n",
    "                      f'Acc: {100.*total_correct/total_samples:.2f}%')\n",
    "        \n",
    "        avg_loss = total_loss / len(self.train_loader)\n",
    "        accuracy = 100. * total_correct / total_samples\n",
    "        return avg_loss, accuracy\n",
    "    \n",
    "    def validate(self):\n",
    "        self.model.eval()\n",
    "        total_loss = 0\n",
    "        all_preds = []\n",
    "        all_targets = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for data, target in self.val_loader:\n",
    "                data, target = data.to(self.device), target.to(self.device)\n",
    "                output = self.model(data)\n",
    "                loss = self.criterion(output, target)\n",
    "                total_loss += loss.item()\n",
    "                \n",
    "                pred = output.argmax(dim=1)\n",
    "                all_preds.extend(pred.cpu().numpy())\n",
    "                all_targets.extend(target.cpu().numpy())\n",
    "        \n",
    "        avg_loss = total_loss / len(self.val_loader)\n",
    "        accuracy = 100. * np.mean(np.array(all_preds) == np.array(all_targets))\n",
    "        f1 = f1_score(all_targets, all_preds, average='weighted')\n",
    "        \n",
    "        return avg_loss, accuracy, f1, all_targets, all_preds\n",
    "    \n",
    "    def train(self, epochs=100, early_stopping_patience=15, save_path='best_ecg_model.pth'):\n",
    "        print(\"Starting ECG ResNet Training...\")\n",
    "        print(f\"Device: {self.device}\")\n",
    "        print(f\"Model parameters: {sum(p.numel() for p in self.model.parameters()):,}\")\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            print(f'\\nEpoch {epoch+1}/{epochs}')\n",
    "            print('-' * 50)\n",
    "            \n",
    "            # Training\n",
    "            train_loss, train_acc = self.train_epoch()\n",
    "            \n",
    "            # Validation\n",
    "            val_loss, val_acc, val_f1, targets, preds = self.validate()\n",
    "            \n",
    "            # Learning rate scheduling\n",
    "            self.scheduler.step(val_loss)\n",
    "            current_lr = self.optimizer.param_groups[0]['lr']\n",
    "            \n",
    "            # Store metrics\n",
    "            self.train_losses.append(train_loss)\n",
    "            self.val_losses.append(val_loss)\n",
    "            self.val_accuracies.append(val_acc)\n",
    "            self.val_f1_scores.append(val_f1)\n",
    "            \n",
    "            print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%')\n",
    "            print(f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%, Val F1: {val_f1:.4f}')\n",
    "            print(f'Learning Rate: {current_lr:.6f}')\n",
    "            \n",
    "            # Early stopping and model saving\n",
    "            if val_loss < self.best_val_loss:\n",
    "                self.best_val_loss = val_loss\n",
    "                self.best_model_state = self.model.state_dict().copy()\n",
    "                self.patience_counter = 0\n",
    "                \n",
    "                # Save best model\n",
    "                torch.save({\n",
    "                    'epoch': epoch + 1,\n",
    "                    'model_state_dict': self.best_model_state,\n",
    "                    'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "                    'val_loss': val_loss,\n",
    "                    'val_accuracy': val_acc,\n",
    "                    'val_f1': val_f1\n",
    "                }, save_path)\n",
    "                print(f'âœ“ New best model saved! Val Loss: {val_loss:.4f}')\n",
    "                \n",
    "            else:\n",
    "                self.patience_counter += 1\n",
    "                if self.patience_counter >= early_stopping_patience:\n",
    "                    print(f'\\nEarly stopping triggered after {epoch+1} epochs')\n",
    "                    break\n",
    "            \n",
    "            # Print classification report every 10 epochs\n",
    "            if (epoch + 1) % 10 == 0:\n",
    "                print(\"\\nClassification Report:\")\n",
    "                print(classification_report(targets, preds, digits=4))\n",
    "        \n",
    "        total_time = time.time() - start_time\n",
    "        print(f'\\nTraining completed in {total_time/60:.1f} minutes')\n",
    "        \n",
    "        # Load best model\n",
    "        if self.best_model_state is not None:\n",
    "            self.model.load_state_dict(self.best_model_state)\n",
    "            print(f'Loaded best model with validation loss: {self.best_val_loss:.4f}')\n",
    "        \n",
    "        return self.model\n",
    "    \n",
    "    def plot_training_history(self):\n",
    "        \"\"\"Plot training curves\"\"\"\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "        epochs = range(1, len(self.train_losses) + 1)\n",
    "        \n",
    "        # Loss curves\n",
    "        axes[0, 0].plot(epochs, self.train_losses, 'b-', label='Train Loss')\n",
    "        axes[0, 0].plot(epochs, self.val_losses, 'r-', label='Val Loss')\n",
    "        axes[0, 0].set_title('Training and Validation Loss')\n",
    "        axes[0, 0].set_xlabel('Epoch')\n",
    "        axes[0, 0].set_ylabel('Loss')\n",
    "        axes[0, 0].legend()\n",
    "        axes[0, 0].grid(True)\n",
    "        \n",
    "        # Accuracy curve\n",
    "        axes[0, 1].plot(epochs, self.val_accuracies, 'g-', label='Val Accuracy')\n",
    "        axes[0, 1].set_title('Validation Accuracy')\n",
    "        axes[0, 1].set_xlabel('Epoch')\n",
    "        axes[0, 1].set_ylabel('Accuracy (%)')\n",
    "        axes[0, 1].legend()\n",
    "        axes[0, 1].grid(True)\n",
    "        \n",
    "        # F1 Score curve\n",
    "        axes[1, 0].plot(epochs, self.val_f1_scores, 'm-', label='Val F1 Score')\n",
    "        axes[1, 0].set_title('Validation F1 Score')\n",
    "        axes[1, 0].set_xlabel('Epoch')\n",
    "        axes[1, 0].set_ylabel('F1 Score')\n",
    "        axes[1, 0].legend()\n",
    "        axes[1, 0].grid(True)\n",
    "        \n",
    "        # Learning rate (if available)\n",
    "        axes[1, 1].text(0.5, 0.5, 'Training Complete', ha='center', va='center', \n",
    "                       transform=axes[1, 1].transAxes, fontsize=16)\n",
    "        axes[1, 1].set_title('Training Summary')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('ecg_training_history.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 14.770471,
   "end_time": "2025-09-24T03:42:57.943822",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-09-24T03:42:43.173351",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
